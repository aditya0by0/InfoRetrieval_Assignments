package com.P02;

import java.io.File;
import java.io.IOException;
import java.nio.file.FileSystems;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Arrays;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import org.apache.commons.io.FileUtils;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.core.LowerCaseFilterFactory;
import org.apache.lucene.analysis.custom.CustomAnalyzer;
import org.apache.lucene.analysis.standard.StandardTokenizerFactory;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.FieldType;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexOptions;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.index.PostingsEnum;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.TermsEnum;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.DocIdSetIterator;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.BytesRef;

public class P02 {

	public static void main(String args[]) throws IOException, ParseException {

		Path indexPath = FileSystems.getDefault().getPath("resources/index");
		File dataDir = new File("resources/data");

		Analyzer analyzer = CustomAnalyzer.builder(Paths.get("src/com/P02/"))
				.withTokenizer(StandardTokenizerFactory.class).addTokenFilter(LowerCaseFilterFactory.class).build();

		Directory directory = FSDirectory.open(indexPath);
		
		//Document indexing:
		indexing(directory, analyzer, dataDir);
		
		//Search setup:
		Set<String> tokens = new HashSet<String>();
		DirectoryReader ireader = DirectoryReader.open(directory);
		IndexSearcher isearcher = new IndexSearcher(ireader);
		QueryParser parser = new QueryParser("contents", analyzer);
		tokens = getTokens(ireader);
		System.out.println(tokens);
		
		System.out.println("Documents that contain 'sunny' and 'exciting':");
		String query = "sunny exciting";
		termIntersection(query, parser, ireader, isearcher);
		System.out.println();

		//Posting list for each token:
		System.out.println("Postings List:");
		postingList(tokens, parser, ireader, isearcher);

		//Posting list for 'sunny' and 'to':
		Set<String> postingTokens = ['sunny', 'to'];
		System.out.println("Postings list for sunny and to:");
		postingList(postingTokens, parser, ireader, isearcher);
		
		ireader.close();
		directory.close();
	}

	private static Set<String> getTokens(DirectoryReader ireader) throws IOException {

		Set<String> tokens = new HashSet<String>();
		int numDocs = ireader.numDocs();

		for (int i = 0; i < numDocs; i++) {
			Terms vector = ireader.getTermVector(i, "contents");
			TermsEnum trms = vector.iterator();
			BytesRef ter;
			
            while ((ter = trms.next()) != null) {
				String termstr = ter.utf8ToString();
				tokens.add(termstr);
			}
		}

		return tokens;
	}

	private static void indexing(Directory directory, Analyzer analyzer, File dataDir) throws IOException {

		IndexWriterConfig config = new IndexWriterConfig(analyzer);
		config.setOpenMode(OpenMode.CREATE);
		IndexWriter iwriter = new IndexWriter(directory, config);
		FieldType fieldType = new FieldType();
		fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);
		fieldType.setStored(true);
        //Default = false (Same as Field.Store.NO)
		fieldType.setTokenized(true);
        //Default = true (Tokenize the content)
		fieldType.setStoreTermVectorOffsets(true);
		fieldType.setStoreTermVectorPayloads(true);
		fieldType.setStoreTermVectorPositions(true);
		fieldType.setStoreTermVectors(true);
		File[] files = dataDir.listFiles();

		for (int i = 0; i < files.length; i++) {
			File f = files[i];
			Document doc = new Document();
            //doc.add(new TextField("contents", new FileReader(f)));
			String text = FileUtils.readFileToString(f);
            //System.out.println(text);
			doc.add(new Field("contents", text, fieldType));
			iwriter.addDocument(doc);
		}

		iwriter.close();
	}
	
	private static void postingList(Set<String> tokens, QueryParser parser, DirectoryReader ireader, IndexSearcher isearcher) throws ParseException, IOException {

		for (String word : tokens) {
			Query query = parser.parse(word);
			TopDocs topDocs = isearcher.search(query, 1000);
			ScoreDoc[] hits = topDocs.scoreDocs;
			Term term = new Term("contents", word);
			System.out.print("[" + word + ":");
			System.out.print(ireader.totalTermFreq(term));
			System.out.print(":" + ireader.docFreq(term) + "]-->");

			for (int i = 0; i < hits.length; i++) {
				int docId = hits[i].doc;
				Terms terms = ireader.getTermVector(docId, "contents");
				TermsEnum te = terms.iterator();
				System.out.print("[" + docId);
				PostingsEnum docsAndPosEnum = null;
				BytesRef bytesRef;

				while ((bytesRef = te.next()) != null) {
					docsAndPosEnum = te.postings(docsAndPosEnum, PostingsEnum.ALL);
					//For each term (iterator next) in this field (field)
					//Iterate over the documents (should only be one)
					int nextDoc = docsAndPosEnum.nextDoc();
					assert nextDoc != DocIdSetIterator.NO_MORE_DOCS;
					final int fr = docsAndPosEnum.freq();
					final int p = docsAndPosEnum.nextPosition();
					final int o = docsAndPosEnum.startOffset();
                    //System.out.println("p="+ p + ", o=" + o + ", l=" + bytesRef.length + ", f=" + fr + ", s=" + bytesRef.utf8ToString());
					String curWord = bytesRef.utf8ToString();

					if (curWord.equals(word)) {
						System.out.print(":" + fr);

						if (fr == 1)
							System.out.print(":[" + o + "]]");
						else if (fr > 1) {
							System.out.print(":[" + o);

							for (int k = 0; k < fr - 1; k++) {
								int np = docsAndPosEnum.nextPosition();
								int offstart = docsAndPosEnum.startOffset();
								System.out.print("," + offstart);
							}

							System.out.print("]]");
						}
					}
				}

				if (i != hits.length - 1)
					System.out.print("->");
			}

			System.out.println();
		}
	}
	
	private static void termIntersection(String word, QueryParser parser, DirectoryReader ireader, IndexSearcher isearcher) throws ParseException, IOException {

		parser.setDefaultOperator(QueryParser.Operator.AND);
		Query query = parser.parse(word);
		//Iterate over words from here
		TopDocs topDocss = isearcher.search(query, 1000);
		ScoreDoc[] hits = topDocss.scoreDocs;
		System.out.println(hits.length);
		List<String> wordss = Arrays.asList(word.split(" "));

		for (int i = 0; i < hits.length; i++) {
			int docId = hits[i].doc;
			Terms terms = ireader.getTermVector(docId, "contents");
			TermsEnum te = terms.iterator();
			System.out.print("[" + docId);
			PostingsEnum docsAndPosEnum = null;
			BytesRef bytesRef;

			while ((bytesRef = te.next()) != null) {
				docsAndPosEnum = te.postings(docsAndPosEnum, PostingsEnum.ALL);
				//For each term (iterator next) in this field (field)
				//Iterate over the docs (should only be one)
				int nextDoc = docsAndPosEnum.nextDoc();
				assert nextDoc != DocIdSetIterator.NO_MORE_DOCS;
				final int fr = docsAndPosEnum.freq();
				final int p = docsAndPosEnum.nextPosition();
				final int o = docsAndPosEnum.startOffset();
				String curWord = bytesRef.utf8ToString();

				if (wordss.contains(curWord)) {
					System.out.print(":" + fr);

					if (fr == 1)
						System.out.print(":[" + o + "]]");
					else if (fr > 1) {
						System.out.print(":[" + o);

                        for (int k = 0; k < fr - 1; k++) {
                            int np = docsAndPosEnum.nextPosition();
                            int offstart = docsAndPosEnum.startOffset();
                            System.out.print("," + offstart);
                        }

                        System.out.print("]]");
					}
				}
			}

			if (i != hits.length - 1)
				System.out.print("->");
		}
	}
}